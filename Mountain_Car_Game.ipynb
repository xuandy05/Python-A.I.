{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mountain Car Game",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xuandy05/Python-A.I./blob/master/Mountain_Car_Game.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XDvssQd64Pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!pip install pyglet==1.3.2 > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5esgX013vPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #error only\n",
        "\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gVTiRhAIC9t",
        "colab_type": "code",
        "outputId": "6099f249-e72b-4da4-b15d-3b7c99ac5b8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXsBlV_BIEvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uToBKZDc4J1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import adam\n",
        "from collections import deque\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(24, input_dim = 2, activation = 'relu'))\n",
        "model.add(Dense(24, activation = 'relu'))\n",
        "model.add(Dense(3, activation = 'linear'))\n",
        "\n",
        "model.compile(optimizer=adam(lr = 0.001), loss='mse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxYU5FoOjLdR",
        "colab_type": "code",
        "outputId": "0a8b61e0-a80c-4791-da84-ace3b71d1781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from collections import deque\n",
        "import random\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "gamma = 0.95\n",
        "epsilon = 1\n",
        "memory = deque(maxlen = 2000)\n",
        "epochs = 1000\n",
        "for i in range(epochs):\n",
        "  state = env.reset()\n",
        "  state = np.reshape(state, [1,2])\n",
        "  done = False\n",
        "  total_reward = 0\n",
        "  for k in range(1500):\n",
        "    e = random.uniform(0,1)\n",
        "    if e < epsilon:\n",
        "      action = env.action_space.sample()\n",
        "    else:\n",
        "      pred = model.predict(state)\n",
        "      action = np.argmax(pred)\n",
        "    next_state, reward, done, info = env.step(action)\n",
        "    next_state = np.reshape(next_state, [1, 2])\n",
        "    memory.append((state, action, reward, next_state, done))\n",
        "    state = next_state \n",
        "    if done:\n",
        "      print(\"Epoch:\", i, \"Score:\", reward)\n",
        "      break\n",
        "  epsilon = min(0.1, epsilon*0.995) \n",
        "  batchsize = 32\n",
        "  if len(memory) > batchsize:\n",
        "    batch = random.sample(memory, batchsize)\n",
        "    for state, action, reward, next_state, done in batch:\n",
        "      target = reward\n",
        "      if not done:\n",
        "        target = reward + gamma*(max(model.predict(next_state)[0]))\n",
        "      target_f = model.predict(state)\n",
        "      target_f[0][action] = target\n",
        "      model.fit(state, target_f, epochs = 1, verbose = 0)\n",
        "      \n",
        "env.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Score: -1.0\n",
            "Epoch: 1 Score: -1.0\n",
            "Epoch: 2 Score: -1.0\n",
            "Epoch: 3 Score: -1.0\n",
            "Epoch: 4 Score: -1.0\n",
            "Epoch: 5 Score: -1.0\n",
            "Epoch: 6 Score: -1.0\n",
            "Epoch: 7 Score: -1.0\n",
            "Epoch: 8 Score: -1.0\n",
            "Epoch: 9 Score: -1.0\n",
            "Epoch: 10 Score: -1.0\n",
            "Epoch: 11 Score: -1.0\n",
            "Epoch: 12 Score: -1.0\n",
            "Epoch: 13 Score: -1.0\n",
            "Epoch: 14 Score: -1.0\n",
            "Epoch: 15 Score: -1.0\n",
            "Epoch: 16 Score: -1.0\n",
            "Epoch: 17 Score: -1.0\n",
            "Epoch: 18 Score: -1.0\n",
            "Epoch: 19 Score: -1.0\n",
            "Epoch: 20 Score: -1.0\n",
            "Epoch: 21 Score: -1.0\n",
            "Epoch: 22 Score: -1.0\n",
            "Epoch: 23 Score: -1.0\n",
            "Epoch: 24 Score: -1.0\n",
            "Epoch: 25 Score: -1.0\n",
            "Epoch: 26 Score: -1.0\n",
            "Epoch: 27 Score: -1.0\n",
            "Epoch: 28 Score: -1.0\n",
            "Epoch: 29 Score: -1.0\n",
            "Epoch: 30 Score: -1.0\n",
            "Epoch: 31 Score: -1.0\n",
            "Epoch: 32 Score: -1.0\n",
            "Epoch: 33 Score: -1.0\n",
            "Epoch: 34 Score: -1.0\n",
            "Epoch: 35 Score: -1.0\n",
            "Epoch: 36 Score: -1.0\n",
            "Epoch: 37 Score: -1.0\n",
            "Epoch: 38 Score: -1.0\n",
            "Epoch: 39 Score: -1.0\n",
            "Epoch: 40 Score: -1.0\n",
            "Epoch: 41 Score: -1.0\n",
            "Epoch: 42 Score: -1.0\n",
            "Epoch: 43 Score: -1.0\n",
            "Epoch: 44 Score: -1.0\n",
            "Epoch: 45 Score: -1.0\n",
            "Epoch: 46 Score: -1.0\n",
            "Epoch: 47 Score: -1.0\n",
            "Epoch: 48 Score: -1.0\n",
            "Epoch: 49 Score: -1.0\n",
            "Epoch: 50 Score: -1.0\n",
            "Epoch: 51 Score: -1.0\n",
            "Epoch: 52 Score: -1.0\n",
            "Epoch: 53 Score: -1.0\n",
            "Epoch: 54 Score: -1.0\n",
            "Epoch: 55 Score: -1.0\n",
            "Epoch: 56 Score: -1.0\n",
            "Epoch: 57 Score: -1.0\n",
            "Epoch: 58 Score: -1.0\n",
            "Epoch: 59 Score: -1.0\n",
            "Epoch: 60 Score: -1.0\n",
            "Epoch: 61 Score: -1.0\n",
            "Epoch: 62 Score: -1.0\n",
            "Epoch: 63 Score: -1.0\n",
            "Epoch: 64 Score: -1.0\n",
            "Epoch: 65 Score: -1.0\n",
            "Epoch: 66 Score: -1.0\n",
            "Epoch: 67 Score: -1.0\n",
            "Epoch: 68 Score: -1.0\n",
            "Epoch: 69 Score: -1.0\n",
            "Epoch: 70 Score: -1.0\n",
            "Epoch: 71 Score: -1.0\n",
            "Epoch: 72 Score: -1.0\n",
            "Epoch: 73 Score: -1.0\n",
            "Epoch: 74 Score: -1.0\n",
            "Epoch: 75 Score: -1.0\n",
            "Epoch: 76 Score: -1.0\n",
            "Epoch: 77 Score: -1.0\n",
            "Epoch: 78 Score: -1.0\n",
            "Epoch: 79 Score: -1.0\n",
            "Epoch: 80 Score: -1.0\n",
            "Epoch: 81 Score: -1.0\n",
            "Epoch: 82 Score: -1.0\n",
            "Epoch: 83 Score: -1.0\n",
            "Epoch: 84 Score: -1.0\n",
            "Epoch: 85 Score: -1.0\n",
            "Epoch: 86 Score: -1.0\n",
            "Epoch: 87 Score: -1.0\n",
            "Epoch: 88 Score: -1.0\n",
            "Epoch: 89 Score: -1.0\n",
            "Epoch: 90 Score: -1.0\n",
            "Epoch: 91 Score: -1.0\n",
            "Epoch: 92 Score: -1.0\n",
            "Epoch: 93 Score: -1.0\n",
            "Epoch: 94 Score: -1.0\n",
            "Epoch: 95 Score: -1.0\n",
            "Epoch: 96 Score: -1.0\n",
            "Epoch: 97 Score: -1.0\n",
            "Epoch: 98 Score: -1.0\n",
            "Epoch: 99 Score: -1.0\n",
            "Epoch: 100 Score: -1.0\n",
            "Epoch: 101 Score: -1.0\n",
            "Epoch: 102 Score: -1.0\n",
            "Epoch: 103 Score: -1.0\n",
            "Epoch: 104 Score: -1.0\n",
            "Epoch: 105 Score: -1.0\n",
            "Epoch: 106 Score: -1.0\n",
            "Epoch: 107 Score: -1.0\n",
            "Epoch: 108 Score: -1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-cffe976d870b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m       \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WsuBteTk3sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = wrap_env(gym.make('MountainCar-v0'))\n",
        "state = env.reset()\n",
        "for time_t in range(500):\n",
        "    env.render()\n",
        "    state = np.reshape(state, [1,2])\n",
        "    pred2 = model.predict(state)\n",
        "    action = np.argmax(pred2)\n",
        "    state, reward, done, _ = env.step(action)\n",
        "    if done:\n",
        "        break\n",
        "        \n",
        "print(time_t)\n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}